<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>API on humus.rocks - soil is life on the rocks</title>
    <link>/tags/api/</link>
    <description>Recent content in API on humus.rocks - soil is life on the rocks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Jun 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/api/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using the terra R package to view, download and analyze Google Earth Engine Images</title>
      <link>/post/2022/06/23/using-the-terra-r-package-to-view-download-and-analyze-google-earth-engine-images/</link>
      <pubDate>Thu, 23 Jun 2022 00:00:00 +0000</pubDate>
      <guid>/post/2022/06/23/using-the-terra-r-package-to-view-download-and-analyze-google-earth-engine-images/</guid>
      <description>Is it possible to use the GDAL “EEDAI” driver (Google Earth Engine Data API Image; https://gdal.org/drivers/raster/eedai.html) via the terra R package to create a SpatRaster from a Google Earth Engine asset?&#xA;One might ask: why bother trying to get data out of Earth Engine? Well, in order to use data in non-proprietary workflows, perform comparisons to non-public datasets, or preserve various products for reproducibility or historic value, we should want to have (at least subsets of) Earth Engine Assets archived as files on our own servers.</description>
    </item>
    <item>
      <title>R-in-the-cloud API for Soil Taxonomy Criteria!</title>
      <link>/post/2020/07/04/r-in-the-cloud-api-for-soil-taxonomy-criteria/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020/07/04/r-in-the-cloud-api-for-soil-taxonomy-criteria/</guid>
      <description>For the KSTLookup Shiny App I am providing “taxon criteria trees” via an R-based API hosted “in the cloud.”&#xA;DigitalOcean provides real-time tracking of various attributes of your “droplets” – here is “HedonisticLogic” my droplet that runs KSTLookup The R API was developed using plumber (https://www.rplumber.io/)&#xA;The service is run “in the cloud” on a “droplet” [Ubuntu 20.04 / R 4.0.2] (https://www.digitalocean.com/)&#xA;HTTP GET provides easy access to the API endpoint: _http://138.</description>
    </item>
  </channel>
</rss>
