<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Exploring lakes, synthetic data, and tibble-SoilProfileCollections | humus.rocks - soil is life on the rocks</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <img src="/images/musick.jpg">
<link href="/css/github.min.css" rel="stylesheet">

  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/categories/">Categories</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h2><span class="title">Exploring lakes, synthetic data, and tibble-SoilProfileCollections</span></h2>
<h3><span class="author">Andrew G. Brown</span>
 | <span class="date">2020/08/15</span></h3>
<p class="terms">
  
  
  Categories: 
  <a href="/categories/r">R</a> 
  <a href="/categories/tidyverse">tidyverse</a> 
  <a href="/categories/tibble">tibble</a> 
  <a href="/categories/aqp">aqp</a> 
  <a href="/categories/soilprofilecollection">SoilProfileCollection</a> 
  <a href="/categories/permute_profile">permute_profile</a> 
  
  
  
  Tags: 
  <a href="/tags/demonstrations">demonstrations</a> 
  
  
</p>
</div>

<main>

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>In this brief tutorial, we will be using the <em>aqp</em> and <em>tidyverse</em> packages for wrangling stratified environmental data from lake cores.</p>
<p>The sample <a href="https://fishandwhistle.net/post/2017/using-the-tidyverse-to-wrangle-core-data/">lake core data</a> from Dewey Dunnington (<a href="http://github.com/paleolimbot">paleolimbot</a> on GitHub) are pretty “typical” of stratified environmental data that you might have kicking around on your hard drive, so that is why we are using it rather than the typical canned soil-database examples from <em>aqp</em> and <em>soilDB</em>. Plus, lake sediments are cool and important troves of information – even where they do not technically meet our criteria for subaqueous soils! I think pedologic knowledge benefits from study of (paleo-)limnology.</p>
<p>Install the required packages if needed. Be sure to get the latest version of <em>aqp</em> off <a href="http://ncss.tech.github.io/aqp/">GitHub</a>. At time of writing this post (August 2020), the features that allow for support for <code>tbl_df</code> and <code>data.table</code> in <em>SoilProfileCollection</em> objects are not yet on CRAN but will be soon.</p>
<pre class="r"><code># install dependencies and CRAN version of packages
install.packages(c(&quot;aqp&quot;,&quot;tidyverse&quot;))
# install development version of aqp
remotes::install_github(&quot;ncss-tech/aqp&quot;, dependencies = FALSE)</code></pre>
<p>Load the packages. We will use <em>ggplot2</em> for most plots and base <em>graphics</em> for <em>SoilProfileCollection</em> objects. There is some commented-out base <em>graphics</em> code that does essentially the same things as the <em>ggplot2</em> code for those who are interested in both.</p>
<pre class="r"><code>library(aqp)
library(tidyverse)
library(ggplot2)</code></pre>
<pre class="r"><code># lake core data from @paleolimbot&#39;s tutorial
# https://fishandwhistle.net/post/2017/using-the-tidyverse-to-wrangle-core-data

# use tribble function to read in a comma-separated set of expressions and create a tibble
pocmaj_raw &lt;- tribble(
  ~sample_id, ~Ca, ~Ti, ~V,  
  &quot;poc15-2 0&quot;, 1036, 1337, 29,
  &quot;poc15-2 0&quot;, 1951, 2427, 31,
  &quot;poc15-2 0&quot;, 1879, 2350, 39,
  &quot;poc15-2 1&quot;, 1488, 2016, 36,
  &quot;poc15-2 2&quot;, 2416, 3270, 79,
  &quot;poc15-2 3&quot;, 2253, 3197, 79,
  &quot;poc15-2 4&quot;, 2372, 3536, 87,
  &quot;poc15-2 5&quot;, 2621, 3850, 86,
  &quot;poc15-2 5&quot;, 2785, 3939, 95,
  &quot;poc15-2 5&quot;, 2500, 3881, 80,
  &quot;maj15-1 0&quot;, 1623, 2104, 73,
  &quot;maj15-1 0&quot;, 1624, 2174, 73,
  &quot;maj15-1 0&quot;, 2407, 2831, 89,
  &quot;maj15-1 1&quot;, 1418, 2409, 70,
  &quot;maj15-1 2&quot;, 1550, 2376, 70,
  &quot;maj15-1 3&quot;, 1448, 2485, 64,
  &quot;maj15-1 4&quot;, 1247, 2414, 57,
  &quot;maj15-1 5&quot;, 1463, 1869, 78,
  &quot;maj15-1 5&quot;, 1269, 1834, 71,
  &quot;maj15-1 5&quot;, 1505, 1989, 94
)

# inspect 
head(pocmaj_raw)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   sample_id    Ca    Ti     V
##   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 poc15-2 0  1036  1337    29
## 2 poc15-2 0  1951  2427    31
## 3 poc15-2 0  1879  2350    39
## 4 poc15-2 1  1488  2016    36
## 5 poc15-2 2  2416  3270    79
## 6 poc15-2 3  2253  3197    79</code></pre>
<p>On inspection we find a field <code>sample_id</code> which contains <em>site</em> (or core)-level and <em>layer</em>-level identifiers.</p>
<p>In this case, the layer identifier is the top depth. It appears that there is a code that relates to general location or waterbody, year, and profile or “core set”. It also appears that the cores were collected in constant increments of 1 meter.</p>
<p>Using top depth as the unique ID for a layer is convenient for field use [ simplicity of bag/core labeling :) ]. It is used similarly in <em>aqp</em> SoilProfileCollection objects, for instance to drive <code>depths&lt;-</code>-based sorting based on ID and top depth. With the new <em>aqp</em> integrity changes this is more consistently used as the primary enforcement on potentially topologically “bad” data.</p>
<p>For Dewey’s data <em>depth-dependent</em> repeated measures by layer are combined with <em>independent</em> repeated measures (replicates) within certain layers. We will try to make use of this.</p>
<div id="dplyr-wrangling-for-input-to-aqp" class="section level2">
<h2><em>dplyr</em> wrangling for input to <em>aqp</em></h2>
<p>We take the raw data and process it for use in the <em>aqp</em> package. We will use the <code>magrittr</code> “pipe” (<code>%&gt;%</code>) operator to pipe or chain-together commands. The <code>%&gt;%</code> facilitates passing variables to functions of the form <code>f(x, y)</code> as <code>x %&gt;% f(y)</code>. This is unnecessary with only a single “step,” but is particularly useful whenever you don’t want to create a bunch of intermediate variables or would like to keep the sequence of your workflow and function dependencies in order and easy to read.</p>
<pre class="r"><code>pocmaj &lt;- pocmaj_raw %&gt;%
  group_by(sample_id) %&gt;%                                         # group replicates together
  summarise(Ca = median(Ca), Ti = median(Ti), V = median(V)) %&gt;%  # calculate median by sample
  separate(sample_id, into = c(&quot;core&quot;, &quot;depth&quot;), sep = &quot; &quot;) %&gt;%   # split site and layer
  mutate(top = as.numeric(depth) * 100,                           # calculate top and bottom depth
         bottom = top + 100)                                      #  (assuming 100 cm increments)</code></pre>
<p>We <code>group_by()</code> <code>sample_id</code> and then <code>summarise()</code> the <code>median()</code> for each <code>sample_id</code> and analyte. This “flattens” a possible many-one relationship for values per depth. After that we <code>separate()</code> <code>sample_id</code> into <code>core</code> (site-level) and <code>depth</code> (layer-level) IDs using <code>" "</code> (a space) as the delimiter. Finally, we we scale <code>depth</code> by a factor of <code>100</code> to convert from meters to centimeters.</p>
<p>We choose <code>median()</code> as our layer-level summary function because it is less sensitive to extreme values than <code>mean()</code>. Other summary statistics could be calculated such as <code>max()</code> for risk-assessment, but not all layers have replicates, so that will not be very useful here.</p>
</div>
<div id="promote-tbl_df-to-soilprofilecollection-via-the-formula-interface" class="section level2">
<h2>Promote <em>tbl_df</em> to <em>SoilProfileCollection</em> via the formula interface</h2>
<p>Once you have a site-level variable, a top and a bottom depth inside a <em>data.frame</em>-like object, you can use the formula interface to “promote” it to a <em>SoilProfileCollection</em> object. This provides user access to to site and layer-level fields via the <code>site()</code> and <code>horizons()</code> S4 methods, respectively.</p>
<pre class="r"><code># promote pocmaj to SoilProfileCollection 
depths(pocmaj) &lt;- core ~ top + bottom</code></pre>
<p>Promoting via the formula interface follows this form <code>depths(your.df) &lt;- siteID ~ topdepth + bottomdepth</code>. <code>your.df</code> is expected to be an object that inherits from <em>data.frame</em>: specifically <em>tbl_df</em> and <em>data.table</em> are supported subclasses in addition to <em>data.frame</em>. <code>core</code>, <code>top</code> and <code>bottom</code> are all columns that exist in <code>pocmaj</code>, and likewise in your own formulas site ID, top and bottom depths must be present in the <code>names()</code> of the object you are promoting to <em>SoilProfileCollection</em>.</p>
<p>Let’s do a visualization of data for a single analyte, Vanadium (<code>V</code>), that we will use through the rest of this tutorial.</p>
<pre class="r"><code># plot soil profile sketch of one variable (V = Vanadium)
plot(pocmaj, color = &quot;V&quot;, name = &quot;hzID&quot;)</code></pre>
<p><img src="/post/2020-08-15-exploring-tibble-lakes-aqp-tidyverse_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="producing-site-level-summaries-from-layer-level-data-with-mutate_profile." class="section level2">
<h2>Producing site-level summaries from layer-level data with <code>mutate_profile</code>.</h2>
<p><code>mutate_profile</code> is a special variety of <code>mutate</code> defined by the <em>aqp</em> package. It contains built-in iteration to support multiple non-standard evaluation expressions that are evaluated in the context of each single profile in a collection.</p>
<p>The result must either resolve to unit length for a profile (a site-level field) or equal in length to the number of layers for that profile (a layer-level field).</p>
<p>Let’s define a function that we can use to summarize arbitrary <em>SoilProfileCollection</em> objects over arbitrary depth intervals.</p>
<pre class="r"><code>#&#39; A custom function to calculate site-level summary stats
#&#39; @name summarize_core
#&#39; @param spc A SoilProfileCollection 
#&#39; @param max.depth Vertical depth to truncate output to [0, max.depth]; default: 600;
#&#39; @return A SoilProfileCollection
summarize_core &lt;- function(spc, max.depth = 600) {
  # max.depth is subject to some basic constraints
  stopifnot(is.numeric(max.depth), length(max.depth) == 1, max.depth &gt; 0)
  
  # truncate profiles to a common depth interval [0, max.depth]
  # suppress aqp::glom warnings about profiles with depth &lt; max.depth
  res &lt;- suppressWarnings(trunc(spc, 0, max.depth))  %&gt;% 
    # for the depth-weighted mean, calculate horizon thickness
    #  this is identical to arithmetic mean if depth interval is constant
    aqp::mutate(layer_wt = bottom - top) %&gt;%
    # mutate_profile performs mutation by profile (site/core)
    mutate_profile(dwt_V = weighted.mean(V, layer_wt),
                   median_V = median(V), 
                   mean_V = mean(V), 
                   sd_V = sd(V))
  return(res)
}</code></pre>
<pre class="r"><code># calculate depth-weighted average V within each core truncated to upper 200cm or 600cm
pocmaj2 &lt;- summarize_core(pocmaj, 200)
pocmaj6 &lt;- summarize_core(pocmaj, 600)

# create unique profile IDs
profile_id(pocmaj2) &lt;- paste0(profile_id(pocmaj2), &quot; [0 - 2 m]&quot;)
profile_id(pocmaj6) &lt;- paste0(profile_id(pocmaj6), &quot; [0 - 6 m]&quot;)</code></pre>
<p>The below code demonstrates effects of total sampling depth on aggregation of stratified layers to “point” or site-level values.</p>
<pre class="r"><code># inspect result (a site-level field calculated from all layers)
pocmaj2and6 &lt;- aqp::union(list(pocmaj2, pocmaj6))

# combined plot
plot(pocmaj2and6, color = &quot;V&quot;, name = &quot;hzID&quot;)</code></pre>
<p><img src="/post/2020-08-15-exploring-tibble-lakes-aqp-tidyverse_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code># inspect
site(pocmaj2and6)[,c(idname(pocmaj2and6),&quot;dwt_V&quot;, &quot;median_V&quot;,&quot;mean_V&quot;,&quot;sd_V&quot;)]</code></pre>
<pre><code>## # A tibble: 4 x 5
##   core              dwt_V median_V mean_V  sd_V
##   &lt;chr&gt;             &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 maj15-1 [0 - 2 m]  71.5     71.5   71.5  2.12
## 2 maj15-1 [0 - 6 m]  68.7     70     68.7  7.31
## 3 poc15-2 [0 - 2 m]  33.5     33.5   33.5  3.54
## 4 poc15-2 [0 - 6 m]  66.3     79     66.3 25.7</code></pre>
<p>The summary statistics reflect what we noticed above in the profile plot and will be important later.</p>
<p>We can take this further and aggregate cores together into groups based on proximity, process, etc. This small two-site example dataset appears to have two different water bodies or areas where cores were collected. One might be interested in aggregate properties of groups of profiles or cores. We only have two unique profiles – but that won’t stop us.</p>
<p>In this case, we want to compare our depth-truncated profiles to the full 6-meter depth profiles to test the effect of sampling depth on observed aggregate values. To do this we will create a synthetic dataset.</p>
</div>
<div id="generating-synthetic-data" class="section level2">
<h2>Generating synthetic data</h2>
<p>We will generate some realizations assuming that all layer boundaries have a standard deviation in depth of 10 centimeters. This could feasibly arise due to sampling issues such as uncertain datum, incomplete recovery, compaction etc. in addition to natural variation in stratigraphy with respect to the continuous spatial variation in analyte concentrations and constant sampling interval.</p>
<pre class="r"><code># assume variation in bottom depth amounts to a standard deviation of about 10% 1m core thickness
# i.e. that normal curve centered at the boundary between 100cm layers has SD of 10cm
horizons(pocmaj2and6)$layer_sd &lt;- 10</code></pre>
<p>To simulate having a bit more data, and to test the effects of depth-based block support, we use the <em>aqp</em> method <code>permute_profile</code>. We also make some simple assumptions for how the analyte varies from profile to profile. This could be expanded considerably, but we are working with very little data here.</p>
<pre class="r"><code># random number seed
set.seed(1234)

# iterate over profiles, generate 100 realizations each, aqp::union result
bigpocmaj &lt;- aqp::union(profileApply(pocmaj2and6, function(p) {
               # use a horizon-level field to produce geometric realizations
               pp &lt;- permute_profile(p, boundary.attr = &quot;layer_sd&quot;)
               
               # naive simulation of varying V values
               #  - gaussian offsets for V
               #  - rounded magnitude of base10 logarithm of profile-specific standard deviation
               #  - value cannot be negative [snaps to zero]
               pp$V &lt;- pmax(0, pp$V + rnorm(n = nrow(pp), mean = 0, 
                                            sd = 10^round(log10(pp$sd_V))))
               
               # create a unique profile ID
               profile_id(pp) &lt;- paste0(unique(p$core), profile_id(pp))
               return(pp)
             }))</code></pre>
</div>
<div id="inspecting-the-synthetic-data" class="section level2">
<h2>Inspecting the synthetic data</h2>
<pre class="r"><code># simulated 400 realizations
#  4 profiles (2 cores, 0-2m and 0-6m case), 100 times each
length(bigpocmaj)</code></pre>
<pre><code>## [1] 400</code></pre>
<pre class="r"><code>library(ggplot2)

h &lt;- horizons(bigpocmaj)
# denormalize site-level core variable to horizon
h$core &lt;- denormalize(bigpocmaj, &quot;core&quot;)

# create factor levels for combined plots from multiple data
littlebig &lt;- rbind(data.frame(pocmaj = &quot;S&quot;, h[,horizonNames(pocmaj)]),
                   data.frame(pocmaj = &quot;O&quot;,  horizons(pocmaj)))

cbPalette &lt;- c(&quot;#009E73&quot;, &quot;#E69F00&quot;)
cbLabels &lt;- c(sprintf(&quot;Original data &amp; density (n = %s, bw = 5)&quot;, sum(!is.na(pocmaj$V))), 
              sprintf(&quot;Synthetic data (n = %s, bins = 100)&quot;, sum(!is.na(bigpocmaj$V))))

ggplot(littlebig, aes(x = V, after_stat(density),
                      color = factor(pocmaj), fill = factor(pocmaj))) + 
  geom_histogram(data = filter(littlebig, pocmaj == &quot;S&quot;), bins = 100) +
  geom_density(data = filter(littlebig, pocmaj == &quot;O&quot;), aes(x = V, fill = NULL), bw = 5) +
  geom_point(data = filter(littlebig, pocmaj == &quot;O&quot;), aes(x = V, y = 0)) +
  theme_bw() + 
  labs(title = &quot;Original v.s. Synthetic bigpocmaj data\n
       Vanadium [ppm] concentrations in all cores and layers&quot;, 
       x = &quot;Vanadium (V), ppm&quot;, y = &quot;Density&quot;, color = &quot;Legend&quot;, fill = &quot;Legend&quot;) +
  scale_fill_manual(values = cbPalette, labels = cbLabels) +
  scale_color_manual(values = cbPalette, labels = cbLabels)</code></pre>
<p><img src="/post/2020-08-15-exploring-tibble-lakes-aqp-tidyverse_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We see bi-modal patterns exhibited in the original data are reflected and fleshed out in our simulated data <code>bigpocmaj</code>. Notice the extreme values at edges of the empirical distribution which are <em>extrapolations</em> beyond range observed in the input data.</p>
</div>
<div id="compare-percentiles" class="section level2">
<h2>Compare percentiles</h2>
<pre class="r"><code># original
round(quantile(pocmaj2and6$V))</code></pre>
<pre><code>##   0%  25%  50%  75% 100% 
##   31   52   70   78   87</code></pre>
<pre class="r"><code>#synthetic
round(quantile(bigpocmaj$V))</code></pre>
<pre><code>##   0%  25%  50%  75% 100% 
##    4   48   69   77  113</code></pre>
<p>A maximum concentration of 114 ppm is obtained in the synthetic sample – which is nearly 30ppm greater than the highest value observed in the original data. For estimation of extrema rather than central tendency approaches may need to be adjusted.</p>
<pre class="r"><code># use aqp::slab to calculate quantiles of V for 25cm &quot;slabs&quot;, grouped by core
#  this is layer-level data result in a data.frame
hbpp &lt;- slab(bigpocmaj, core ~ V, slab.structure = 25)
hbpp &lt;- hbpp[complete.cases(hbpp),]

# small jitter to prevent overplotting of medians
hbpp$p.q50 &lt;- jitter(hbpp$p.q50, amount = 0.5)

cbPalette &lt;- c(&quot;#009E73&quot;, &quot;#E69F00&quot;, &quot;#cc79a7&quot;, &quot;#0072b2&quot;)

# plot
ggplot(hbpp, aes(x = V, y = top)) + 
       scale_y_reverse() +
       labs(title = &quot;Synthetic `bigpocmaj` - 25cm Slabs\nMedian V [ppm] &amp; [0.05, 0.95] quantiles&quot;, 
            x = &quot;Vanadium (V), ppm&quot;, y = &quot;Depth, cm&quot;, color = &quot;Legend&quot;) +
       geom_path(data = hbpp, aes(x = p.q50, y = top, color = factor(core)), linetype = 2) +
       geom_path(data = hbpp, aes(x = p.q5, y = top, color = factor(core)), linetype = 3) + 
       geom_path(data = hbpp, aes(x = p.q95, y = top, color = factor(core)), linetype = 3) +
       scale_color_manual(values = cbPalette)</code></pre>
<p><img src="/post/2020-08-15-exploring-tibble-lakes-aqp-tidyverse_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<!--
Here are two base **R** plots you can try on your own for comparison to _ggplot2_.


```r
plot(y = bigpocmaj$top, x = bigpocmaj$V, type="n", ylim = c(max(pretty(bigpocmaj$top)), 0))
plts <- lapply(aqp::split(bigpocmaj, f = "core"), function(bpp) {
  # calculate depth quantiles
  sbpp <- slab(bpp, ~ V, slab.structure = 10)

  # calculate color
  scol <- match(bpp$core, unique(bigpocmaj$core))
  linetype <- ifelse(max(sbpp$top[!is.na(sbpp$p.q50)]) > 201, 3, 1)

  lines(y = sbpp$top, x = sbpp$p.q5, col = scol, lwd = 1, lty = linetype)
  lines(y = sbpp$top, x = sbpp$p.q50, col = scol, lwd = 2, lty = linetype)
  lines(y = sbpp$top, x = sbpp$p.q95, col = scol, lwd = 1, lty = linetype)
})

# raw line plot
plot(y = bigpocmaj$top, x = bigpocmaj$V, type="n", ylim = c(max(pretty(bigpocmaj$top)), 0))
plts <- profileApply(bigpocmaj, function(p) {
   lines(y = p$top, x = p$V, col = match(p$core, unique(bigpocmaj$core)))
  })
```
-->
<pre class="r"><code># calculate site-level summary stats for each simulated profile
simulated.groups &lt;- summarize_core(bigpocmaj, 600) %&gt;% 
  # group by &quot;core&quot; (original profile ID)
  aqp::group_by(core) %&gt;%
  # summarize profile stats by original core group
  aqp::summarize(mean_dwt_V = mean(dwt_V), 
                 mean_median_V = mean(median_V), 
                 mean_mean_V = mean(mean_V), 
                 mean_sd_V = mean(sd_V),
                 sd_dwt_V = sd(dwt_V), 
                 sd_median_V = sd(median_V), 
                 sd_mean_V = sd(mean_V), 
                 sd_sd_V = sd(sd_V))</code></pre>
<pre><code>## converting core to a factor</code></pre>
<pre class="r"><code># inspect
simulated.groups</code></pre>
<pre><code>## # A tibble: 4 x 9
##   core  mean_dwt_V mean_median_V mean_mean_V mean_sd_V sd_dwt_V sd_median_V
##   &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;
## 1 maj1…       71.7          71.5        71.5      2.23    0.760       0.731
## 2 maj1…       68.5          68.6        68.6     11.7     4.53        4.83 
## 3 poc1…       32.4          32.8        32.8      8.45    6.86        6.78 
## 4 poc1…       65.5          75.5        66.0     27.2     3.83        5.58 
## # … with 2 more variables: sd_mean_V &lt;dbl&gt;, sd_sd_V &lt;dbl&gt;</code></pre>
<p>So, we may not completely believe the values coming out of this naive simulation, but it shows the workflow for how you would summarize a larger amount of data and also possibly how to begin comparing observed data to synthetic data. The output generally reflects the pattern we saw from the individual profiles – with a little more <em>fuzziness</em>.</p>
</div>
<div id="commentary" class="section level2">
<h2>Commentary</h2>
<p>We assume standard deviations for core depth ranges are constant at 10 cm / 10% of a 1-meter slice. This produces a slight perturbation to the default geometry without dramatically influencing the overall degree of aggregation. We further assume that the variation in the <em>analyte</em> can be modeled for a layer based on the original value for that layer plus a gaussian offset related to the whole-profile variation in analyte.</p>
<p>There is a tacit assumption in this line of analysis that there is a single “mode” within a particular profile for the depth-distribution that can be described relative to a known prior value for a layer plus a profile-level mean and standard deviation. Much more complex models of these relationships can be developed than are demonstrated here.</p>
<p>Ideally, simulation parameters would be based on <em>more than one profile</em> and would be <em>depth-dependent</em>. <em>permute_profile</em> only deals in Gaussian offsets of boundaries. his type of analysis can be useful for demonstrating sensitivity to factors that affect scaling of observed properties – specifically the depth range sampled, core recovery, variation in analytes compared to “random noise” or group/global variance parameters, etc.</p>
</div>
<div id="next-steps" class="section level2">
<h2>Next steps</h2>
<p>Functions in <em>aqp</em> such as <code>generalize_hz</code> <code>hzTransitionProbabilies</code> <code>genhzTableToAdjMat</code> <code>mostLikelyHzSequence</code> are useful for identifying of “depth modes” in soils data. Dylan Beaudette has developed several routines for visualizing generalized horizon patterns such as <code>plotSoilRelationGraph</code> and plots that show simultaneous horizon transition probabilities for multiple generalized horizons across depth.</p>
<p><a href="https://ncss-tech.github.io/stats_for_soil_survey/chapters/2_data/genhz_homework.html">Here</a> is a tutorial I developed on initial steps for developing generalized horizon concepts for the Statistics for Soil Survey course. It needs to be expanded to demonstrate some of the graphical and modeling components. Code like what Dewey used in his demo linked at the beginning of this tutorial to create depth-dendograms would also be useful, especially considering <code>slice</code> or <code>slabbed</code> profiles.</p>
</div>

</main>

  <footer>
  <script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script async src="//yihui.name/js/center-img.js"></script>

<script src="/js/highlight.min.js"></script>
<script src="/js/r.min.js"></script>
<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>

  
  <hr/>
  <p>Andrew G. Brown (<a href="https://humus.rocks">humus.rocks</a> | <a href="https://github.com/brownag">GitHub</a> | <a href="https://twitter.com/humus_rocks">Twitter</a>)</p>
<p><a href="https://github.com/yihui/hugo-xmin">XMin Theme by Yihui Xie</a></p>

  
  </footer>
  </body>
</html>

