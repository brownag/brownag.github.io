<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on humus.rocks - soil is life on the rocks</title>
    <link>/categories/r/</link>
    <description>Recent content in R on humus.rocks - soil is life on the rocks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 16 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Exploring the tidyverse, lakes, synthetic data, and tibble-SoilProfileCollections</title>
      <link>/post/2020/08/16/exploring-tibble-lakes-aqp-tidyverse/</link>
      <pubDate>Sun, 16 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/08/16/exploring-tibble-lakes-aqp-tidyverse/</guid>
      <description>In this brief tutorial, we will be using the aqp and tidyverse R packages for wrangling stratified environmental data from lake cores.
The sample lake core data from Dewey Dunnington’s tidyverse core-data-wrangling tutorial are pretty “typical” of raw, stratified environmental data that you might have kicking around on your hard drive. It also has a lot of information content despite very small (subset) size – which you will see in his tutorial and in what follows.</description>
    </item>
    
    <item>
      <title>Shiny Pedon Summary: Loafercreek &amp; Gopheridge demo</title>
      <link>/post/2020/08/03/shiny-pedon-summary-now-on-shinyapps-io-w-loafercreek-gopheridge-demo-data/</link>
      <pubDate>Mon, 03 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/08/03/shiny-pedon-summary-now-on-shinyapps-io-w-loafercreek-gopheridge-demo-data/</guid>
      <description>This is the Shiny &amp;ldquo;flexdashboard&amp;rdquo; version of the &amp;ldquo;pedon summary report&amp;rdquo; originally developed by Dylan Beaudette. I have developed and refined this dashboard periodically over several years. I developed it initially as a very simple interface to semi-automate viewing profile sketches and report generation based on mapunit, series name and taxon kind.
https://brownag.shinyapps.io/ShinyPedonSummary/
This tool has been part of the ncss-tech soilReports package for a while now, but recent revisions improve efficiency and produce static output matching the original report Dylan developed.</description>
    </item>
    
    <item>
      <title>Transitioning to hugo &#43; R blogdown-driven blog</title>
      <link>/post/2020/08/01/transitioning-to-hugo-r-blogdown-driven-blog/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/08/01/transitioning-to-hugo-r-blogdown-driven-blog/</guid>
      <description>The humus.rocks website has used Drupal 7 for the last 2.5 years. I have only tapped a fraction of the resources that are available to me in the Drupal platform &amp;ndash; using it essentially as a glorified RSS feed aggregator and &amp;ldquo;blog&amp;rdquo;.
I would much rather write my blogs in markdown &amp;ndash; and then I can extend that to Rmarkdown for my more code-oriented topics or any case where I need to generate some content in a programmatic way.</description>
    </item>
    
    <item>
      <title>Estimations of Soil Depth with aqp</title>
      <link>/post/2020/07/13/estimations-with-algorithms-for-quantitative-pedology/</link>
      <pubDate>Mon, 13 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/07/13/estimations-with-algorithms-for-quantitative-pedology/</guid>
      <description>Estimation of soil depth in aqp R package Estimation functions for soils try to calculate unknown properties based on existing observations and known relationships. The term pedotransfer function was coined by Johan Bouma as “translating data we have into what we need.” Soil surveys, and especially the primary descriptions collected by field soil scientists, offer many opportunities for leveraging this type of information.
In Algorithms for Quantitative Pedology aqp, the heuristics are defined in terms of R code.</description>
    </item>
    
    <item>
      <title>First post using Hugo &#43; blogdown</title>
      <link>/post/2020/07/05/first-post-using-hugo-blogdown/</link>
      <pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/07/05/first-post-using-hugo-blogdown/</guid>
      <description>  This is a header This is some regular text.
# this is some R code (with syntax highlighting) for (i in 1:10) { if (i %% 2 == 0) { print(sprintf(&amp;quot;this is a string %s&amp;quot;, i)) } } ## [1] &amp;quot;this is a string 2&amp;quot; ## [1] &amp;quot;this is a string 4&amp;quot; ## [1] &amp;quot;this is a string 6&amp;quot; ## [1] &amp;quot;this is a string 8&amp;quot; ## [1] &amp;quot;this is a string 10&amp;quot;  </description>
    </item>
    
    <item>
      <title>R-in-the-cloud API for Soil Taxonomy Criteria!</title>
      <link>/post/2020/07/04/r-in-the-cloud-api-for-soil-taxonomy-criteria/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/07/04/r-in-the-cloud-api-for-soil-taxonomy-criteria/</guid>
      <description>For the KSTLookup Shiny App I am providing “taxon criteria trees” via an R-based API hosted “in the cloud.”
DigitalOcean provides real-time tracking of various attributes of your “droplets” – here is “HedonisticLogic” my droplet that runs KSTLookup
  The R API was developed using plumber (https://www.rplumber.io/)
 The service is run “in the cloud” on a “droplet” [Ubuntu 20.04 / R 4.0.2] (https://www.digitalocean.com/)
 HTTP GET provides easy access to the API endpoint: _http://138.</description>
    </item>
    
    <item>
      <title>Claves para la Taxonomía del Suelos</title>
      <link>/post/2020/06/23/claves-para-la-taxonomia-kstlookup/</link>
      <pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/06/23/claves-para-la-taxonomia-kstlookup/</guid>
      <description>Buscar Criterios de Taxón La Taxonomía del Suelo es un idioma utilizado en todo el mundo.
Hice que mi algoritmo funcionara con las Claves españolas. ¡Echale un vistazo!
https://brownag.shinyapps.io/KSTLookup</description>
    </item>
    
    <item>
      <title>US Soil Taxonomy Preceding Taxa App</title>
      <link>/post/2020/06/13/soil-taxonomy-preceding-taxa-app/</link>
      <pubDate>Sat, 13 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/06/13/soil-taxonomy-preceding-taxa-app/</guid>
      <description>Continuing on my work with the underlying structure and logic of Soil Taxonomy, I have created another derivative of my text-mined database.
https://brownag.shinyapps.io/KSTPreceding/
This Shiny app shows all taxa that precede the specified taxon in the classification “sequence” specified by the Keys to Soil Taxonomy.
This type of visualization is very relevant to the logic of the Keys, because in some ways, taxa are as much what they are, as what they are not.</description>
    </item>
    
    <item>
      <title>US Soil Taxonomy Taxon Criteria App</title>
      <link>/post/2020/06/10/soil-taxonomy-taxon-criteria-app/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/06/10/soil-taxonomy-taxon-criteria-app/</guid>
      <description>Here is a basic Shiny app interface to a new database I developed from performing text mining analyses on the Keys to Soil Taxonomy (12th edition). This is alpha version of the “KSTLookup” Shiny app – a new tool for viewing criteria associated with taxa at the subgroup to order level in U.S. Soil Taxonomy.
https://brownag.shinyapps.io/KSTLookup/
Enter a taxon name such as “Spodosols”, “Aeric Endoaquepts”, “Glacistels” and see the tree of criteria – essentially a “pathway” leading to that specific taxon.</description>
    </item>
    
    <item>
      <title>Plot Water Level &amp; NOAA Weather Data</title>
      <link>/post/2020/06/05/plot-henry-waterlevel-nearby-noaa-precip/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/06/05/plot-henry-waterlevel-nearby-noaa-precip/</guid>
      <description>This is a demonstration of how to plot water level data from the Henry Mount Soil Climate database with precipitation data from a nearby NOAA weather station.
The demo uses two functions I recently added to the soilDB package (available on GitHub)
 get_NOAA_stations_nearXY- find all stations near a specified latitude/longitude and bounding box (limit 1000)
 get_NOAA_GHCND - get GHCND data (daily summaries) by station IDs, datatypes and years</description>
    </item>
    
    <item>
      <title>Mollic epipedon thickness requirement</title>
      <link>/post/2020/04/30/mollic-epipedon-thickness-requirement/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/04/30/mollic-epipedon-thickness-requirement/</guid>
      <description>[This functionality has been live in aqp since version 1.21+]
Here is a demonstration of some new functionality I am working on for evaluating taxonomic criteria with aqp.
mollic.thickness.requirement calculates the minimum thickness of the materials meeting other requirements for a mollic epipedon, per criterion 6 in U.S. Soil Taxonomy (12th edition). I have used it for QC of pedon data, and also to assess questions about how frequently e.</description>
    </item>
    
    <item>
      <title>soilDB 2.5 back on CRAN!</title>
      <link>/post/2020/01/28/soildb-2-5-back-on-cran/</link>
      <pubDate>Tue, 28 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/01/28/soildb-2-5-back-on-cran/</guid>
      <description>CRAN release: soilDB 2.5 https://github.com/ncss-tech/soilDB
This is a release of soilDB with new functionality and documentation, updates to conform with aqp 1.19, as well as bug-fixes and other quality-of-life enhancements.
 https://github.com/ncss-tech/soilDB https://cran.r-project.org/web/packages/soilDB/index.html http://ncss-tech.github.io/soilDB/docs/  Notably: we are back on CRAN. Tests and examples have been altered to minimize likelihood of failure on CRAN check farm machines, which has been an on-going issue.
By making tests that contact remote APIs skip if missing the nasis_local ODBC connection, we can effectively filter tests to run only on the local (work) machine.</description>
    </item>
    
    <item>
      <title>aqp 1.19 release and demos</title>
      <link>/post/2020/01/27/aqp-1-19-release-and-demos/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/01/27/aqp-1-19-release-and-demos/</guid>
      <description>CRAN release: aqp (Algorithms for Quantitative Pedology) 1.19  Recent Changes CRAN release aqp 1.19 (2020-01-22)  new functions: hzDesgn(), get horizon designations from a SPC new functions: hzdesgnname()/hzdesgnname()&amp;lt;- and hztexclname()/hztexclname()&amp;lt;- get/set column containing horizon designations and texture classes better error/logic handling for glom()    Demonstrations aqp::glom() demo Here is a demonstration of checking cambic horizon texture criteria with glom() in SSURGO components from Yosemite National Park: - http://ncss-tech.</description>
    </item>
    
    <item>
      <title>loafercreek - aqp profileApply() tutorial</title>
      <link>/post/2018/12/25/loafercreek-aqp-profileapply-tutorial/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/12/25/loafercreek-aqp-profileapply-tutorial/</guid>
      <description>This is a tutorial (worked examples and exercises) demonstrating use of the profileApply() function from the R package aqp.
http://ncss-tech.github.io/AQP/demos/profileApply/loafercreek.html
It loads a dataset, called loafercreek from the R package soilDB.
The analysis is supported by the package sharpshootR. These packages are in large part developed by Dylan Beaudette, but there now are many contributors within NCSS.
Loafercreek the dataset is a collection of mostly moderately deep Ultic Haploxeralfs on metavolcanic rock from the CA630 soil survey area (parts of Calaveras and Tuolumne Counties.</description>
    </item>
    
  </channel>
</rss>